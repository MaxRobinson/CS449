{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 12 - Programming Assignment\n",
    "\n",
    "## Directions\n",
    "\n",
    "There are general instructions on Blackboard and in the Syllabus for Programming Assignments. This Notebook also has instructions specific to this assignment. Read all the instructions carefully and make sure you understand them. Please ask questions on the discussion boards or email me at `EN605.445@gmail.com` if you do not understand something.\n",
    "\n",
    "<div style=\"background: mistyrose; color: firebrick; border: 2px solid darkred; padding: 5px; margin: 10px;\">\n",
    "You must follow the directions *exactly* or you will get a 0 on the assignment.\n",
    "</div>\n",
    "\n",
    "You must submit a zip file of your assignment and associated files (if there are any) to Blackboard. The zip file will be named after you JHED ID: `<jhed_id>.zip`. It will not include any other information. Inside this zip file should be the following directory structure:\n",
    "\n",
    "```\n",
    "<jhed_id>\n",
    "    |\n",
    "    +--module-01-programming.ipynb\n",
    "    +--module-01-programming.html\n",
    "    +--(any other files)\n",
    "```\n",
    "\n",
    "For example, do not name  your directory `programming_assignment_01` and do not name your directory `smith122_pr1` or any else. It must be only your JHED ID. Make sure you submit both an .ipynb and .html version of your *completed* notebook. You can generate the HTML version using:\n",
    "\n",
    "> ipython nbconvert [notebookname].ipynb\n",
    "\n",
    "or use the File menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "In this assignment you will be using the mushroom data from the Decision Tree module:\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "\n",
    "The assignment is to write a program that will learn and apply a Naive Bayes Classifier for this problem. You'll first need to calculate all of the necessary probabilities (don't forget to use +1 smoothing) using a `learn` function. You'll then need to have a `classify` function that takes your probabilities, a List of instances (possibly a list of 1) and returns a List of Tuples. Each Tuple is a class and the *normalized* probability of that class. The List should be sorted so that the probabilities are in descending order. For example,\n",
    "\n",
    "```\n",
    "[(\"e\", 0.98), (\"p\", 0.02)]\n",
    "```\n",
    "\n",
    "when calculating the error rate of your classifier, you should pick the class with the highest probability (the first one in the list).\n",
    "\n",
    "As a reminder, the Naive Bayes Classifier generates the un-normalized probabilities from the numerator of Bayes Rule:\n",
    "\n",
    "$$P(C|A) \\propto P(A|C)P(C)$$\n",
    "\n",
    "where C is the class and A are the attributes (data). Since the normalizer of Bayes Rule is the *sum* of all possible numerators and you have to calculate them all, the normalizer is just the sum of the probabilities.\n",
    "\n",
    "You'll also need an `evaluate` function as before. You should use the $error\\_rate$ again.\n",
    "\n",
    "Use the same testing procedure as last time, on two randomized subsets of the data:\n",
    "\n",
    "1. learn the probabilities for set 1\n",
    "2. classify set 2\n",
    "3. evaluate the predictions\n",
    "4. learn the probabilities for set 2\n",
    "5. classify set 1\n",
    "6. evalute the the predictions\n",
    "7. average the classification error.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division # so that 1/2 = 0.5 and not 0\n",
    "from IPython.core.display import *\n",
    "import csv, math, copy, random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**attributes_domain**   \n",
    "A helper function to return a dictionary of attributes, and the domains possible for that attribute.    \n",
    "\n",
    "This is used to start the Naive Bayes algorithm with the appropriate possible attributes and their domains. \n",
    "A '?' attribute is added to every domain in case a record is missing a value for a given domain. **In the Record** the value for that domain is expected to have a '?' indicating that for that record the attribute value is unknown.  \n",
    "\n",
    "__input__:    \n",
    "None\n",
    "\n",
    "__return__: \n",
    "+ attributes: a dictionary of attribute names as keys and the attributes domain as a list of strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attributes_domains():\n",
    "    return {\n",
    "        'label': ['e', 'p', '?'],\n",
    "        'cap-shape': ['b', 'c', 'x', 'f', 'k', 's', '?'],\n",
    "        'cap-surface': ['f', 'g', 'y', 's', '?'],\n",
    "        'cap-color': ['n', 'b', 'c', 'g', 'r', 'p', 'u', 'e', 'w', 'y', '?'],\n",
    "        'bruises?': ['t', 'f', '?'],\n",
    "        'odor': ['a', 'l', 'c', 'y', 'f', 'm', 'n', 'p', 's', '?'],\n",
    "        'gill-attachment': ['a', 'd', 'f', 'n', '?'],\n",
    "        'gill-spacing': ['c', 'w', 'd', '?'],\n",
    "        'gill-size': ['b', 'n', '?'],\n",
    "        'gill-color': ['k', 'n', 'b', 'h', 'g', 'r', 'o', 'p', 'u', 'e', 'w', 'y', '?'],\n",
    "        'stalk-shape': ['e', 't', '?'],\n",
    "        'salk-root': ['b', 'c', 'u', 'e', 'z', 'r', '?'],\n",
    "        'stalk-surface-above-ring': ['f', 'y', 'k', 's', '?'],\n",
    "        'stalk-surface-below-ring': ['f', 'y', 'k', 's', '?'],\n",
    "        'stalk-color-above-ring': ['n', 'b', 'c', 'g', 'o', 'p', 'e', 'w', 'y', '?'],\n",
    "        'stalk-color-below-ring': ['n', 'b', 'c', 'g', 'o', 'p', 'e', 'w', 'y', '?'],\n",
    "        'veil-type': ['p', 'u', '?'],\n",
    "        'veil-color': ['n', 'o', 'w', 'y', '?'],\n",
    "        'ring-number': ['n', 'o', 't', '?'],\n",
    "        'ring-type': ['c', 'e', 'f', 'l', 'n', 'p', 's', 'z', '?'],\n",
    "        'spore-print-color': ['k', 'n', 'b', 'h', 'r', 'o', 'u', 'w', 'y', '?'],\n",
    "        'population': ['a', 'c', 'n', 's', 'v', 'y', '?'],\n",
    "        'habitat': ['g', 'l', 'm', 'p', 'u', 'w', 'd', '?'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get_positive_label**   \n",
    "A helper function to return the positive label for this implimentation of a Naive Bayes Classifier. Used incase the positive label were to change. \"positive\" in this context is simply derived from the data set, and that it is a __POSITIVE__ thing to be able to eat a mushroom, thus the __label__ for the dataset __e__ is \"Positive\". This is the ONLY reason it's called positive. \n",
    "\n",
    "The label is used in calculating the information gain, as well as determining the majority label of an attribute. \n",
    "\n",
    "\n",
    "__input__:   \n",
    "None\n",
    "\n",
    "__return__: \n",
    "+ the label, a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_positive_label():\n",
    "    return 'e'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get_negative_label**   \n",
    "A helper function to return the negative label for this implimentation of a Naive Bayes Classifier. Used incase the negative label were to change. \"Negative\" in this context is simply derived from the data set, and that it is a __NEGATIVE__ thing to eat a Poisonous mushroom, thus the __label__ for the dataset __p__ is \"Negative\". This is the ONLY reason it's called negative. \n",
    "\n",
    "The label is used in calculating the information gain, as well as determining the majority label of an attribute. \n",
    "\n",
    "\n",
    "__input__:   \n",
    "None\n",
    "\n",
    "__return__: \n",
    "+ the label, a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_negative_label():\n",
    "    return 'p'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create_record**   \n",
    "A helper function to create a record to be used in the Naive Bayes Classifier, given a record from the csv file.    \n",
    "\n",
    "Creates a dictionary that maps the attribute_name to the value of that attribute for a given record.    \n",
    "\n",
    "This is used to transform all of the data read in from the csv file into an easily usable dictionary for Naive Bayes Classifier.   \n",
    "\n",
    "\n",
    "__input__:\n",
    "+ csv_record: a list of strings\n",
    "\n",
    "__return__: \n",
    "+ a dictionary that maps attribute_names to the value for that attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_record(csv_record):\n",
    "    return {\n",
    "        'label': csv_record[0],\n",
    "        'cap-shape': csv_record[1],\n",
    "        'cap-surface': csv_record[2],\n",
    "        'cap-color': csv_record[3],\n",
    "        'bruises?': csv_record[4],\n",
    "        'odor': csv_record[5],\n",
    "        'gill-attachment': csv_record[6],\n",
    "        'gill-spacing': csv_record[7],\n",
    "        'gill-size': csv_record[8],\n",
    "        'gill-color': csv_record[9],\n",
    "        'stalk-shape': csv_record[10],\n",
    "        'salk-root': csv_record[11],\n",
    "        'stalk-surface-above-ring': csv_record[12],\n",
    "        'stalk-surface-below-ring': csv_record[13],\n",
    "        'stalk-color-above-ring': csv_record[14],\n",
    "        'stalk-color-below-ring': csv_record[15],\n",
    "        'veil-type': csv_record[16],\n",
    "        'veil-color': csv_record[17],\n",
    "        'ring-number': csv_record[18],\n",
    "        'ring-type': csv_record[19],\n",
    "        'spore-print-color': csv_record[20],\n",
    "        'population': csv_record[21],\n",
    "        'habitat': csv_record[22],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create_distribution_dict**   \n",
    "A helper function to create a dictionary that holds the Naive Bayes Classifier distibutions for all of the $P(a_i|c_i)$ probabilities, for each $A$ where $A$ is all attributes and $a_i$ is a domain for a specific attribute.     \n",
    "\n",
    "The dictionary has the following strucutre: \n",
    "```python\n",
    "{\n",
    "    (attribute, attribute_domain_value, 'label', label_value) : value\n",
    "}\n",
    "```\n",
    "The key allows us to specify for which attribute, and for what domain value we are creating the distribution for, and the 'label' label_value allow us to create the \"Given $c_i$\" part of the distribution. \n",
    "\n",
    "This dictionary is used first to create an overall count of each disitbution, and then is later used to hold the actual probability distibution for the Naive Bayes Classifier. \n",
    "\n",
    "**Note** that the distibution for \"counting\" is initialized to 1. This is to account for the \"+1\" smoothing that is needed for calculating the probabilities later on for the $P(f_i | c)$ which describes the probability. \n",
    "\n",
    "\n",
    "This is an important method for the algorithm because this function specifies how the distibution is stored.\n",
    "\n",
    "__input__:   \n",
    "None\n",
    "\n",
    "__return__:    \n",
    "+ a dictionary with the structure specified in the above discription. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_distribution_dict():\n",
    "    attributes_with_domains = attributes_domains()\n",
    "\n",
    "    distribution = {}\n",
    "\n",
    "    for attribute, domains in attributes_with_domains.iteritems():\n",
    "        if attribute == 'label':\n",
    "            continue\n",
    "        for domain in domains:\n",
    "            distribution[(attribute, domain, 'label', get_positive_label())] = 1\n",
    "            distribution[(attribute, domain, 'label', get_negative_label())] = 1\n",
    "\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**read_file**   \n",
    "A helper function to read in the data from a CSV file, and transform it into a list of records, as described in the `create_record` description. \n",
    "\n",
    "**NOTE**: If not given a path to a file, it **assumes** that the file is in your local directory, from which you are running this notebook. It also **assumes** that the file it is reading is \"agaricus-lepiota.data\".    \n",
    "The file can be found at https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\n",
    "\n",
    "Please also note that this file is the expected format of input for this **entire** Naive Bayes Classifier implementation. \n",
    "Please do not try to run this with other data that is not in this format, or have the same bounds as this data set. \n",
    "\n",
    "__input__:   \n",
    "+ path (optional): the path to the csv file you wish to read in.\n",
    "\n",
    "__return__: \n",
    "+ records: A list of records. Records have the shape described by the `create_record` description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(path=None):\n",
    "    if path is None:\n",
    "        path = 'agaricus-lepiota.data'\n",
    "    with open(path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        csv_list = list(reader)\n",
    "\n",
    "    records = []\n",
    "    for value in csv_list:\n",
    "        records.append(create_record(value))\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create_distribution_key**   \n",
    "A helper function the key needed to access a given probability in the Naive Bayes Distribution dictionary, described in `create_distribution_dict`.\n",
    "\n",
    "\n",
    "__input__:\n",
    "+ attribute: a String that specifies the attribute for the probability to access\n",
    "+ domain: a string that specifies the domain value for the probability to access\n",
    "+ label_value: a string that specifies which classification label to use when accessing the probability.\n",
    "\n",
    "__return__: \n",
    "+ a tuple with the structure: (attribute_name, domain_value, 'label', label_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_distribution_key(attribute, domain_value, label_value):\n",
    "    return (attribute, domain_value, 'label', label_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**put_value_in_distribution**   \n",
    "A helper function to increment the count by 1, in the distribution dictionary, of a given key. \n",
    "\n",
    "Used when counting the number of occurenses of a particular $A=a_i, C=c_i$ when building out the distribution of the training set.\n",
    "\n",
    "\n",
    "__input__:\n",
    "+ distribution: a dictionary with the structure specified by `create_distribution_dict`\n",
    "+ attribute: a String that specifies the attribute for the probability to access\n",
    "+ domain: a string that specifies the domain value for the probability to access\n",
    "+ label_value: a string that specifies which classification label to use when accessing the probability.\n",
    "\n",
    "__return__: \n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def put_value_in_distribution(distribution, attribute, domain_value, label_value):\n",
    "    key = create_distribution_key(attribute, domain_value, label_value)\n",
    "    distribution[key] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get_label_count**   \n",
    "A helper function that returns the number of records that have a given label. \n",
    "\n",
    "This is used to get the total number of records with a given label.   \n",
    "This value is then used when calculating the normalized probabilites of the distribution, $$P(f_i | c_i) = \\frac{Num((f_i,c_i)) + 1}{Num(c_i) + 1}$$\n",
    "\n",
    "Specifically the $Num(c_i)$ part.\n",
    "\n",
    "\n",
    "__input__:   \n",
    "+ records: a list of records. \n",
    "\n",
    "__return__: \n",
    "+ count: the number of records with the specified label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_label_count(records, label):\n",
    "    count = 0\n",
    "    for record in records:\n",
    "        if record['label'] == label:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create_percentages**   \n",
    "A helper function that, given a distibution of counts for $(f_i, c_i)$ calculates the probability according to: \n",
    "$$P(f_i | c_i) = \\frac{Num((f_i,c_i)) + 1}{Num(c_i) + 1}$$   \n",
    "\n",
    "The distribution already contains the \"count\" for the probability, the $Num((f_i,c_i)) + 1$ part. To calculte the probability, we just divide by the dividend which is passed in in the form of the count for the positive and negative lables. \n",
    "\n",
    "For each key in the distribution, we determine which $c_i$ it uses, and divide by the appropriate dividend. \n",
    "\n",
    "These percentages or distributions are then used during the classification step. \n",
    "\n",
    "__input__:   \n",
    "+ pos_count: an int, the number of records with the \"positive\" label in the training set. \n",
    "+ neg_count: an int, the number of records with the \"negative\" label in the training set. \n",
    "+ distribution: a dictionary, with the structure specified in `create_distribution_dict`\n",
    "\n",
    "__return__: \n",
    "+ distribution: a dictionary, with the structure specified in `create_distribution_dict`, now with values that are probabilites rather than raw counts. Probability is calculated according to the above formula. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_percentages(pos_count, neg_count, distribution):\n",
    "    pos_count_plus_1 = pos_count + 1\n",
    "    neg_count_plus_1 = neg_count + 1\n",
    "\n",
    "    pos_label = get_positive_label()\n",
    "    neg_label = get_negative_label()\n",
    "\n",
    "    for key in distribution:\n",
    "        if key[3] == pos_label:\n",
    "            distribution[key] = distribution[key] / pos_count_plus_1\n",
    "        elif key[3] == neg_label:\n",
    "            distribution[key] = distribution[key] / neg_count_plus_1\n",
    "\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**learn**   \n",
    "The main function that learns the distribution for the Naive Bayes Classifier. \n",
    "\n",
    "The function works as follows: \n",
    "+ Create initial distribution counts\n",
    "+ get positive label counts\n",
    "+ get negative label counts\n",
    "+ for each record in the training set: \n",
    "    + For each attribute, and domain_value for the attribute: \n",
    "        + put the value into the distribution (i.e incriment the value for that attribute, domain, and label tuple\n",
    "            + the Corresponding value in the distribution is (Attribute, domain_value, 'label', actual label for record)\n",
    "+ change the distribution from counts to probabilities\n",
    "+ add special entries in the distribution for the Probability of each possible label. \n",
    "    + the Probability of a given label is as follows: $P(c_i) = \\frac{Num(c_i)}{Size Of Training Set}$\n",
    "\n",
    "\n",
    "We then return the learned distribution, as our Naive Bayes Classifier.\n",
    "\n",
    "__input__:   \n",
    "+ records: a list of records, as described by the `create_record` function.\n",
    "\n",
    "__return__: \n",
    "+ distribution: a dictionary, with the structure specified in `create_distribution_dict`, with values that are the probabilites for each $A$ and $C$ so that we have $P(A=a_i | C=c_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learn(records):\n",
    "    distribution = create_distribution_dict()\n",
    "    pos_count = get_label_count(records, get_positive_label())\n",
    "    neg_count = get_label_count(records, get_negative_label())\n",
    "\n",
    "    for record in records:\n",
    "        for attribute, domain_value in record.iteritems():\n",
    "            if attribute == 'label':\n",
    "                continue\n",
    "            put_value_in_distribution(distribution, attribute, domain_value, record['label'])\n",
    "\n",
    "    distribution = create_percentages(pos_count, neg_count, distribution)\n",
    "    distribution[('label', get_positive_label())] = pos_count / (pos_count + neg_count)\n",
    "    distribution[('label', get_negative_label())] = neg_count / (pos_count + neg_count)\n",
    "\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**calculate_probability_of**   \n",
    "A helper function that calculates the **un_normalized** probability of a given instance (record), for a given label.    \n",
    "\n",
    "The **un_normalized** probability is caclulated as follows:\n",
    "$$P(c_i) \\prod_i P(f_i | c_i)$$\n",
    "\n",
    "Where $f_i$ is a given attribute and attributes value, and c_i is a given label. \n",
    "\n",
    "To calculate this, we itterate throught the instance's (record's) attributes, and values for the attributes, create the key into the distribution from the attribute and attribute's value and the label we are wishing to calculate the probability for.    \n",
    "\n",
    "This is then multiplied to the running product of the other probabilities. \n",
    "The running product is initialized to the $P(c_i)$ to take care of the initial multiplicative term.    \n",
    "\n",
    "The un_normalized probability is then returned. \n",
    "\n",
    "\n",
    "\n",
    "This is used when classifying a record, to get the probability that the record should have a certain label. \n",
    "This is important because this probability is then normalized after all probabilities are gotten for all labels, and then used to determing how likely a record is part of a given class label. \n",
    "\n",
    "\n",
    "__input__:   \n",
    "+ distribution: a dictionary, with the structure specified in `create_distribution_dict`, with values that are the probabilites.\n",
    "+ instance: a record, as described by `create_record`\n",
    "+ labelL: a string that describes a given label value. \n",
    "\n",
    "__return__: \n",
    "+ un_normalized_prob: a float that represents the un_normalized probability that a record belongs to the given class label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_probability_of(distribution, instance, label):\n",
    "    un_normalized_prob = distribution[('label', label)]\n",
    "    for attribute, domain_value in instance.iteritems():\n",
    "        if attribute == 'label':\n",
    "            continue\n",
    "        key = create_distribution_key(attribute, domain_value, label)\n",
    "        un_normalized_prob *= distribution[key]\n",
    "\n",
    "    return un_normalized_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**normalize**   \n",
    "A helper function that normalizes a list of probabilities. The list of probabilities is for a **single record**, and should have the following structure: \n",
    "```python\n",
    "[(label, probability), (label, probability)]\n",
    "```\n",
    "These probabilities should be **un_normalized** probabilities for each label.\n",
    "\n",
    "This function normalizes the probabilities by summing the probabilities for each label together, then calculating the normalized probability for each label by dividing the probability for that label by the sum of all the probabilities. \n",
    "\n",
    "This normalized probability is then placed into a new list with the same structure and same corresponding label. \n",
    "\n",
    "The list of normalized probabilies is then **SORTED** in descending order. I.E. the label with the most likely possibility is in index position **0** for the list of probabilities**\n",
    "\n",
    "This new normalized list of probabilities is then returned. \n",
    "\n",
    "\n",
    "This function is important because this calculates the probabilities that are then used to choose which label should be used to describe a record. **This is done during validation**\n",
    "\n",
    "\n",
    "__input__:   \n",
    "+ probability_list: a list of tuples, as described by: `[(label, probability), (label, probability)]`\n",
    "\n",
    "__return__: \n",
    "+ normalized_list: a list of tuples, as described by: `[(label, probability), (label, probability)]` with the probabilities being normalized as described above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(probability_list):\n",
    "    sum_of_probabilities = 0\n",
    "\n",
    "    normalized_list = []\n",
    "\n",
    "    for prob_tuple in probability_list:\n",
    "        sum_of_probabilities += prob_tuple[1]\n",
    "\n",
    "    for prob_tuple in probability_list:\n",
    "        normalized_prob = prob_tuple[1] / sum_of_probabilities\n",
    "\n",
    "        normalized_list.append((prob_tuple[0], normalized_prob))\n",
    "\n",
    "    normalized_list.sort(key=lambda x: x[1], reverse=True)\n",
    "    return normalized_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classify_instance**   \n",
    "A helper that does most of the work to classifiy a given instance of a record.    \n",
    "\n",
    "It works as follows: \n",
    "+ create a list of possible labels\n",
    "+ initialize results list. \n",
    "+ for each label\n",
    "    + calculate the **un_normalized** probability of the instance using `calculate_probabily_of` \n",
    "    + add the probability to the results list as a tuple of (label, un_normalized probability)\n",
    "+ normalize the probabilities, using `normalize`\n",
    "    + note that now the list of results (a list of tuples) is now sorted in descending order by the value of the probability\n",
    "\n",
    "+ return the normalized probabilities for that instance of a record. \n",
    "\n",
    "This is important because this list describes the probabilities that this record should have a given label. \n",
    "The **First tuple** in the list is the tuple with the label that has the **Hightest** probability for this record.\n",
    "\n",
    "\n",
    "__input__:   \n",
    "+ distribution: a dictionary, with the structure specified in `create_distribution_dict`, with values that are the probabilites.\n",
    "+ instace: a record, as described by `create_record` \n",
    "\n",
    "__return__: \n",
    "+ probability_results: a List of tuples with the structure as: `[(label, normalized probability), (label, normalized probability)]` sorted in descending order by probability.   \n",
    "**NOTE**: This is these are the probabilites for a **SINGLE** record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_instance(distribution, instance):\n",
    "    labels = [get_positive_label(), get_negative_label()]\n",
    "\n",
    "    probability_results = []\n",
    "\n",
    "    for label in labels:\n",
    "        probability = calculate_probability_of(distribution, instance, label)\n",
    "        probability_results.append((label, probability))\n",
    "\n",
    "    probability_results = normalize(probability_results)\n",
    "\n",
    "    return probability_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**classify**   \n",
    "A function to classify a list of instances(records). \n",
    "\n",
    "Given a list of instances (records), classify each instance using `classify_instance` and put the result into a result list. Return the result list after each instance has been classified. \n",
    "\n",
    "The Structure of the **return list** will be a **List of lists** where each inner list is a **list of tuples**, as described by the `classify_instance` function. An example will look as follows: \n",
    "```python\n",
    "[ [('e', .999),('p', .001)], [('p', .78), ('e', .22)] ] \n",
    "```\n",
    "\n",
    "The first list `[('e', .999),('p', .001)]` corresponds to the probabilities for the first instance in the `instances` list and the second list to the second instance of the `instances` list. So on and so forth for each entry in the `instances` list. \n",
    "\n",
    "\n",
    "\n",
    "__input__:   \n",
    "+ distribution: a dictionary, with the structure specified in `create_distribution_dict`, with values that are the probabilites.\n",
    "+ instace: a record, as described by `create_record` \n",
    "\n",
    "__return__: \n",
    "+ results: a list of lists of tuples as described above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(distribution, instances):\n",
    "    results = []\n",
    "    for instance in instances:\n",
    "        results.append(classify_instance(distribution, instance))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**evaluate**   \n",
    "The main evaluation method. Uses a simple $\\frac{ Num Errors}{total Data Points}$ to calculate the error rate of the Naive Bayes Classifier.\n",
    "\n",
    "Given a list of records (test_data) and a list of predicted classifications for that data set, run through both lists, and compire the label for the record to the predicted classification. If they do not match, increase the number of errors seen. \n",
    "\n",
    "The label for the predicted classification is at position 0 of the predicted probabilities list, and position 0 of the tuple for that holds the label and probability of that label. i.e. for a classifications list that is as follows: \n",
    "```python\n",
    "[ [('e', .999),('p', .001)], [('p', .78), ('e', .22)] ] \n",
    "```\n",
    "The predicted label for record 1 is `'e'` since the corresponding predicted probabilities are `[('e', .999),('p', .001)]`, the most likely label is at position 0 in the list, since they are sorted from most probable to least probable. Position 0 of the list gives us `('e', .999)`. The label for this selected probability is then at position 0 of the tuple, which gives us `'e'`.     \n",
    "This label is then compared to the actual label for the record for correctness. \n",
    "\n",
    "\n",
    "Return the number of erros seen divided by the total number of data points. This is the error rate. \n",
    "\n",
    "__input__:   \n",
    "+ test_data: a list of records\n",
    "+ classifications: a list of lists of tuples, as described by the `classify` function. \n",
    "\n",
    "__return__: \n",
    "+ error_rate: a float that represents the number of errors / total number of data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(test_data, classifications):\n",
    "    number_of_errors = 0\n",
    "    for record, classification in zip(test_data, classifications):\n",
    "        if record['label'] != classification[0][0]:\n",
    "            number_of_errors += 1\n",
    "\n",
    "    return number_of_errors/len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "Put your main function calls here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Training Sets\n",
    "Shuffle training set to ensure no bias from data order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_records = read_file()\n",
    "\n",
    "random.shuffle(test_records)\n",
    "\n",
    "half_way = int(math.floor(len(test_records)/2))\n",
    "set_1 = test_records[:half_way]\n",
    "set_2 = test_records[half_way:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Naive Bayes 1 on Set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distro_1 = learn(set_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Predicted Classifications for Set 2 From Naive Bayes 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b1_c2 = classify(distro_1, set_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Predicted Set 2 against Actual Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate for Naive Bayes 1 with Set 2 = 0.0467749876908\n"
     ]
    }
   ],
   "source": [
    "evaluation_b1_c2 = evaluate(set_2, b1_c2)\n",
    "print \"Error Rate for Naive Bayes 1 with Set 2 = {}\".format(evaluation_b1_c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Naive Bayes 2 on Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distro_2 = learn(set_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Predicted Classifications for Set 1 From Naive Bayes 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b2_c1 = classify(distro_2, set_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Predicted Set 1 against Actual Set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate for Naive Bayes 2 with Set 1 = 0.0558838010832\n"
     ]
    }
   ],
   "source": [
    "evaluation_b2_c1 = evaluate(set_1, b2_c1)\n",
    "print \"Error Rate for Naive Bayes 2 with Set 1 = {}\".format(evaluation_b2_c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Average Error for Both Naive Bayes Distrobutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error Rate: 0.051329394387\n"
     ]
    }
   ],
   "source": [
    "average_error = (evaluation_b1_c2 + evaluation_b2_c1)/2\n",
    "print \"Average Error Rate: {}\".format(average_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
